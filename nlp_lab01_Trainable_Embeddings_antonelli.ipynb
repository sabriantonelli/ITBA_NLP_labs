{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8w8DRjGAHzyG"
   },
   "outputs": [],
   "source": [
    "# Usar keras 2.2.5\n",
    "# conda install -c conda-forge keras=2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rnLq6p7aHzyK",
    "outputId": "255c8cf0-d833-43d7-ba3a-d54b6f7d3cdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "l6qXmkzsHzyO",
    "outputId": "fa6d6dc3-10ad-4700-ba52-937835e0a839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0KnibsN1xUk3"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb as dataset\n",
    "#from keras.datasets import reuters as dataset\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvpowIEOHzyT"
   },
   "source": [
    "# Cargamos y analizamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n4ra2gF4HzyU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Applications/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Applications/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Primer hyperparámetro\n",
    "num_words=30000\n",
    "\n",
    "(training_data, training_targets), (testing_data, testing_targets) = dataset.load_data(num_words=num_words+2)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYWTLfB1xUlI",
    "outputId": "26d6415d-9d0d-432c-d093-bfbd194cd2f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: [0 1]\n",
      "Number of unique words: 30000\n"
     ]
    }
   ],
   "source": [
    "# Tengo dos categorías: Sentimiento positivo (1) o sentimiento negativo (0)\n",
    "num_categories = len(np.unique(targets))\n",
    "print(\"Categories:\", np.unique(targets))\n",
    "# Tengo num_words palabras únicas en el vocabulario\n",
    "print(\"Number of unique words:\", len(np.unique(np.hstack(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lZ-DUxtxUlT",
    "outputId": "90196e97-9517-4612-f47f-a2774fe5279e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Review length: 234.75892\n",
      "Standard Deviation: 173\n"
     ]
    }
   ],
   "source": [
    "# Longitudes promedio de los comentarios de las películas\n",
    "length = [len(i) for i in data]\n",
    "print(\"Average Review length:\", np.mean(length))\n",
    "print(\"Standard Deviation:\", round(np.std(length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGeDrxcRHzya"
   },
   "source": [
    "# Impresión de comentario preprocesado con su etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnT33-acxUlZ",
    "outputId": "8ba4c18f-526e-48ff-dc49-4fb0febcafbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Imprimo cometario i'esimo con su clasificación de sentimiento\n",
    "i = 0\n",
    "print(\"Label:\", targets[i])\n",
    "# Las comentarios ya están preprocesados\n",
    "print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSVq9thIxUlh",
    "outputId": "247a85d6-602a-4998-b640-14458882eeda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fawn:34701', 'tsukino:52006', 'nunnery:52007', 'sonja:16816', 'vani:63951', 'woods:1408', 'spiders:16115', 'hanging:2345', 'woody:2289', 'trawling:52008', \"hold's:52009\", 'comically:11307', 'localized:40830', 'disobeying:30568', \"'royale:52010\", \"harpo's:40831\", 'canet:52011', 'aileen:19313', 'acurately:52012', \"diplomat's:52013\", 'rickman:25242', 'arranged:6746', 'rumbustious:52014', 'familiarness:52015', \"spider':52016\", 'hahahah:68804', \"wood':52017\", 'transvestism:40833', \"hangin':34702\", 'bringing:2338', 'seamier:40834', 'wooded:34703', 'bravora:52018', 'grueling:16817', 'wooden:1636', 'wednesday:16818', \"'prix:52019\", 'altagracia:34704', 'circuitry:52020', 'crotch:11585', 'busybody:57766', \"tart'n'tangy:52021\", 'burgade:14129', 'thrace:52023', \"tom's:11038\", 'snuggles:52025', 'francesco:29114', 'complainers:52027', 'templarios:52125', '272:40835', '273:52028', 'zaniacs:52130', '275:34706', 'consenting:27631', 'snuggled:40836', 'inanimate:15492', 'uality:52030', 'bronte:11926', 'errors:4010', 'dialogs:3230', \"yomada's:52031\", \"madman's:34707\", 'dialoge:30585', 'usenet:52033', 'videodrome:40837', \"kid':26338\", 'pawed:52034', \"'girlfriend':30569\", \"'pleasure:52035\", \"'reloaded':52036\", \"kazakos':40839\", 'rocque:52037', 'mailings:52038', 'brainwashed:11927', 'mcanally:16819', \"tom'':52039\", 'kurupt:25243', 'affiliated:21905', 'babaganoosh:52040', \"noe's:40840\", 'quart:40841', 'kids:359', 'uplifting:5034', 'controversy:7093', 'kida:21906', 'kidd:23379', \"error':52041\", 'neurologist:52042', 'spotty:18510', 'cobblers:30570', 'projection:9878', 'fastforwarding:40842', 'sters:52043', \"eggar's:52044\", 'etherything:52045', 'gateshead:40843', 'airball:34708', 'unsinkable:25244', 'stern:7180', \"cervi's:52046\"]\n"
     ]
    }
   ],
   "source": [
    "# Bajamos diccionario de palabras a indices\n",
    "index = dataset.get_word_index()\n",
    "print([f'{k}:{v}' for k,v in index.items()][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrmkTbXyHzyf",
    "outputId": "3201bdc5-4d75-4871-d843-90dfa9399225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['34701:fawn', '52006:tsukino', '52007:nunnery', '16816:sonja', '63951:vani', '1408:woods', '16115:spiders', '2345:hanging', '2289:woody', '52008:trawling', \"52009:hold's\", '11307:comically', '40830:localized', '30568:disobeying', \"52010:'royale\", \"40831:harpo's\", '52011:canet', '19313:aileen', '52012:acurately', \"52013:diplomat's\", '25242:rickman', '6746:arranged', '52014:rumbustious', '52015:familiarness', \"52016:spider'\", '68804:hahahah', \"52017:wood'\", '40833:transvestism', \"34702:hangin'\", '2338:bringing', '40834:seamier', '34703:wooded', '52018:bravora', '16817:grueling', '1636:wooden', '16818:wednesday', \"52019:'prix\", '34704:altagracia', '52020:circuitry', '11585:crotch', '57766:busybody', \"52021:tart'n'tangy\", '14129:burgade', '52023:thrace', \"11038:tom's\", '52025:snuggles', '29114:francesco', '52027:complainers', '52125:templarios', '40835:272', '52028:273', '52130:zaniacs', '34706:275', '27631:consenting', '40836:snuggled', '15492:inanimate', '52030:uality', '11926:bronte', '4010:errors', '3230:dialogs', \"52031:yomada's\", \"34707:madman's\", '30585:dialoge', '52033:usenet', '40837:videodrome', \"26338:kid'\", '52034:pawed', \"30569:'girlfriend'\", \"52035:'pleasure\", \"52036:'reloaded'\", \"40839:kazakos'\", '52037:rocque', '52038:mailings', '11927:brainwashed', '16819:mcanally', \"52039:tom''\", '25243:kurupt', '21905:affiliated', '52040:babaganoosh', \"40840:noe's\", '40841:quart', '359:kids', '5034:uplifting', '7093:controversy', '21906:kida', '23379:kidd', \"52041:error'\", '52042:neurologist', '18510:spotty', '30570:cobblers', '9878:projection', '40842:fastforwarding', '52043:sters', \"52044:eggar's\", '52045:etherything', '40843:gateshead', '34708:airball', '25244:unsinkable', '7180:stern', \"52046:cervi's\"]\n"
     ]
    }
   ],
   "source": [
    "# Armo diccionario reverso: de indices a palabras\n",
    "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
    "print([f'{k}:{v}' for k,v in reverse_index.items()][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lhq6d5MWHzyi",
    "outputId": "93ed6a0a-ef09-418d-af4e-8073f5decdce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "\n",
      "# big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their stomachs sickening that men actually wore them and the music is just # trash that plays over and over again in almost every scene there is trashy music boobs and paramedics taking away bodies and the gym still doesn't close for # all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"
     ]
    }
   ],
   "source": [
    "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[1]] )\n",
    "print(data[1])\n",
    "print()\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBL_1v2eHzym"
   },
   "source": [
    "# Padding y formateo de data para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HifepVsJxUlo"
   },
   "outputs": [],
   "source": [
    "# Hyperparametro - Longitud máxima de comentario\n",
    "maxlen=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Tb8Mf33exUlu"
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(data,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fq-c12e5xUl8",
    "outputId": "1bd8f272-73fe-4e35-8e9f-e9aaac4ae93d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Verificamos que todos tengan longitud 1000\n",
    "print(len(data[0]))\n",
    "print(np.array([len(d) for d in data]).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jXBIUZaNxUmD"
   },
   "outputs": [],
   "source": [
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Gwma-IqxUmK",
    "outputId": "6593df7f-f16b-4ea9-af4e-8e32feb6b2bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nn5uQK-ynGVC",
    "outputId": "e85e3fb5-5280-4232-81a4-f5b79fff9f2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   21,  846, 5518],\n",
       "       [   0,    0,    0, ..., 2302,    7,  470],\n",
       "       [   0,    0,    0, ...,   34, 2005, 2643]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bplIZHWNUXo"
   },
   "source": [
    "# Armar una MLP con one-hot encoding para resolver el problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MQ51AMr2Nbok"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HFYmsr3bm3Ev"
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "shape = (data.size, data.max()+1)\n",
    "one_hot = np.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "YV5eg2fDNdtk"
   },
   "outputs": [],
   "source": [
    "# usar maxlen y num_words para calcular la entrada\n",
    "\n",
    "\n",
    "# Utilizar una sola capa\n",
    "model = Sequential()\n",
    "\n",
    "## TODO\n",
    "salida_densa = 1\n",
    "input_shape = one_hot.shape\n",
    "model.add(Dense(salida_densa, input_shape=input_shape, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXqCIIv6OWe8",
    "outputId": "42502b1c-d614-44fc-faf8-b7de8f286503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50000000, 1)       30003     \n",
      "=================================================================\n",
      "Total params: 30,003\n",
      "Trainable params: 30,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-RLYV5QPBEX"
   },
   "source": [
    "## ¿Por que no es viable esta red?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnvzV5wiPKjs"
   },
   "source": [
    "# Armar una MLP usando Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ecjdmUczPIVf"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Flatten, Dropout, Conv1D, MaxPooling1D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "OPTlDXslPO0o"
   },
   "outputs": [],
   "source": [
    "# Cantidad de palabras totales contando las reservadas\n",
    "nb_words=num_words+3\n",
    "# Tamano del embedding. Es un hiperparámetro y puede modificarlo\n",
    "embed_dim=128\n",
    "salida_capa_densa = 1\n",
    "dropout=0.5 # Hiperparámetro\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim, input_length=maxlen, trainable=True))\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(dropout))\n",
    "model.add(Dense(salida_capa_densa, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qTs8XKCLPVqX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 128)         3840384   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 128001    \n",
      "=================================================================\n",
      "Total params: 3,968,385\n",
      "Trainable params: 3,968,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "J6bygoYSP1PW"
   },
   "outputs": [],
   "source": [
    "# MODIFIQUE HYPERPARAMS A GUSTO\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "U4tv5kkjPuaj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 87s 55ms/step - loss: 0.4368 - accuracy: 0.7809\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 84s 54ms/step - loss: 0.0920 - accuracy: 0.9726\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 91s 58ms/step - loss: 0.0158 - accuracy: 0.9983\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 90s 57ms/step - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 81s 52ms/step - loss: 9.2911e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa4c9bab100>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data,targets,batch_size=32,epochs=5)#,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNPXfSxWQRI3"
   },
   "source": [
    "# Armar una CNN\n",
    "Abajo hay un ejemplo de arquitectur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "C8Yi3_A4V5AS"
   },
   "outputs": [],
   "source": [
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_12 (Embedding)     (None, 1000, 32)          960096    \n",
    "# _________________________________________________________________\n",
    "# conv1d_7 (Conv1D)            (None, 1000, 64)          14400     \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_4 (MaxPooling1 (None, 500, 64)           0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_8 (Conv1D)            (None, 500, 128)          57472     \n",
    "# _________________________________________________________________\n",
    "# global_max_pooling1d_4 (Glob (None, 128)               0         \n",
    "# _________________________________________________________________\n",
    "# dropout_4 (Dropout)          (None, 128)               0         \n",
    "# _________________________________________________________________\n",
    "# dense_19 (Dense)             (None, 46)                5934      \n",
    "# =================================================================\n",
    "\n",
    "# Cantidad de palabras totales contando las reservadas\n",
    "nb_words=num_words+3\n",
    "# Tamano del embedding. Es un hiperparámetro y puede modificarlo\n",
    "embed_dim=128\n",
    "salida_capa_densa = 1\n",
    "dropout=0.5 # Hiperparámetro\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim, input_length=maxlen, trainable=True))\n",
    "model.add(Conv1D(filters=64, kernel_size=8, activation='relu' , input_shape = (maxlen,embed_dim)))\n",
    "model.add(MaxPooling1D())\n",
    "#model.add(Flatten())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(salida_capa_densa, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 32)          960096    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 993, 64)           16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 496, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 496, 64)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 496, 1)            65        \n",
      "=================================================================\n",
      "Total params: 976,609\n",
      "Trainable params: 976,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ssxu2rPVV_d_"
   },
   "outputs": [],
   "source": [
    "# MODIFIQUE HYPERPARAMS A GUSTO\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "AzXyAjAvxUmW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 143s 114ms/step - loss: 0.6824 - accuracy: 0.5272 - val_loss: 0.6745 - val_accuracy: 0.5325\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 140s 112ms/step - loss: 0.6709 - accuracy: 0.5418 - val_loss: 0.6743 - val_accuracy: 0.5330\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 157s 126ms/step - loss: 0.6683 - accuracy: 0.5432 - val_loss: 0.6744 - val_accuracy: 0.5333\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 151s 121ms/step - loss: 0.6667 - accuracy: 0.5458 - val_loss: 0.6739 - val_accuracy: 0.5338\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 153s 122ms/step - loss: 0.6645 - accuracy: 0.5428 - val_loss: 0.6741 - val_accuracy: 0.5342\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 145s 116ms/step - loss: 0.6631 - accuracy: 0.5444 - val_loss: 0.6746 - val_accuracy: 0.5342\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 131s 105ms/step - loss: 0.6610 - accuracy: 0.5498 - val_loss: 0.6757 - val_accuracy: 0.5342\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 139s 111ms/step - loss: 0.6588 - accuracy: 0.5511 - val_loss: 0.6761 - val_accuracy: 0.5338\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 138s 111ms/step - loss: 0.6575 - accuracy: 0.5504 - val_loss: 0.6780 - val_accuracy: 0.5337\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 139s 112ms/step - loss: 0.6561 - accuracy: 0.5528 - val_loss: 0.6798 - val_accuracy: 0.5332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa4b3b1b7c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data,targets,batch_size=32,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copia de Trainable Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
