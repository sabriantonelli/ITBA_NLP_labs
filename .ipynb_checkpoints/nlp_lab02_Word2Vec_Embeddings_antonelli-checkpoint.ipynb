{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r-mpXuyJT9UO"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences # input sentences are of various lengths. To handle a large amount of data, it is more efficient to keep the length of the data constant. https://mmsankosho.com/en/nlp-simple-introduction-to-pad_sequences-and-timeseriesgenerator/\n",
    "import numpy as np\n",
    "import gensim # NLP no supervisado. https://www.tutorialspoint.com/gensim/gensim_quick_guide.htm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qILN_kfqIp0x"
   },
   "source": [
    "# Dataset: IMDB Movie reviews sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FgeQzCkIjMM",
    "outputId": "dbcb8471-2304-4c39-dd3d-2ad627e0ba52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n",
      "17473536/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "num_words=30000\n",
    "INDEX_FROM=3  # idx 0 => PAD, idx 1 => START, idx 2 => OOV (out of vocab.) # se deja espacio libre para usar codigos\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=num_words+2,)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEiPTqOBT_V7",
    "outputId": "7b86580d-8d50-48e5-fff2-382bfb3dce73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: [0 1]\n",
      "Number of unique words: 30000\n"
     ]
    }
   ],
   "source": [
    "num_words=len(np.unique(np.hstack(data))) #hstack: Stack arrays in sequence horizontally (column wise).\n",
    "print(\"Categories:\", np.unique(targets)) \n",
    "print(\"Number of unique words:\", num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "Cr9SDpjui8Oy",
    "outputId": "44f71a4d-d121-4789-edf5-df617f559d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**target sample:**\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ec162adb-916c-49c7-95e0-257bb5dd8bb1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec162adb-916c-49c7-95e0-257bb5dd8bb1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ec162adb-916c-49c7-95e0-257bb5dd8bb1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ec162adb-916c-49c7-95e0-257bb5dd8bb1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  0\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd_data = pd.DataFrame(data)\n",
    "#pd_data.head()\n",
    "pd_training = pd.DataFrame(training_data)\n",
    "pd_target = pd.DataFrame(training_targets)\n",
    "print('**target sample:**');\n",
    "pd_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "OXXbCgAQku1b",
    "outputId": "28460ea8-7aa2-4f30-9f86-e17b6aee926a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample de training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4cd22f14-5a7b-441b-8886-81decd213892\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cd22f14-5a7b-441b-8886-81decd213892')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4cd22f14-5a7b-441b-8886-81decd213892 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4cd22f14-5a7b-441b-8886-81decd213892');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, ...\n",
       "1  [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463,...\n",
       "2  [1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5...\n",
       "3  [1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 1...\n",
       "4  [1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 1..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('sample de training');\n",
    "pd_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJnK5I5il2Yz",
    "outputId": "e3182bf8-b0ce-4d92-b29e-6c4d88a6ac2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd_training[0][3]) #traigo un sample x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nef02I90wigz"
   },
   "source": [
    "Agregar el siguiente archivo al Google Drive\n",
    "\n",
    "https://drive.google.com/open?id=1K5r423yMxBb1Yz2uDT7lto60lu1jqEjl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9mmn9fpUIY6",
    "outputId": "1b53fff1-890d-4f92-de46-39dea7bad0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tOvUY-MUJGH",
    "outputId": "4a9b6c72-301d-4e87-fd35-f97f719b1e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Review length: 234.75892\n",
      "Standard Deviation: 173\n"
     ]
    }
   ],
   "source": [
    "length = [len(i) for i in data]\n",
    "print(\"Average Review length:\", np.mean(length))\n",
    "print(\"Standard Deviation:\", round(np.std(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHY8EhzvUdzt",
    "outputId": "5d5e1c59-a19b-4353-cb9c-1c0553d209d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "#veamos el target y las palabras ejemplos para una instancia particular\n",
    "print(\"Label:\", targets[0])\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSnvI2LuM5So"
   },
   "source": [
    "# Traemos el vocabulario y armamos indice reverso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lY7mGCLUf0M",
    "outputId": "aafdc55c-4171-4957-bb1b-c1310e25f666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "# big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their stomachs sickening that men actually wore them and the music is just # trash that plays over and over again in almost every scene there is trashy music boobs and paramedics taking away bodies and the gym still doesn't close for # all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"
     ]
    }
   ],
   "source": [
    "# le asigna a cada palabra un index\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
    "decoded = \" \".join( [reverse_index.get(i - INDEX_FROM, \"#\") for i in data[1]] )\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6R5A_xU9cGM2"
   },
   "outputs": [],
   "source": [
    "#embeddings\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/GoogleNews-vectors-negative300.bin\", binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDEVfp7RY489",
    "outputId": "733dac8c-3f54-4c26-b873-1e391783f34e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.13085938,  0.00842285,  0.03344727, -0.05883789,  0.04003906,\n",
       "       -0.14257812,  0.04931641, -0.16894531,  0.20898438,  0.11962891,\n",
       "        0.18066406, -0.25      , -0.10400391, -0.10742188, -0.01879883,\n",
       "        0.05200195, -0.00216675,  0.06445312,  0.14453125, -0.04541016,\n",
       "        0.16113281, -0.01611328, -0.03088379,  0.08447266,  0.16210938,\n",
       "        0.04467773, -0.15527344,  0.25390625,  0.33984375,  0.00756836,\n",
       "       -0.25585938, -0.01733398, -0.03295898,  0.16308594, -0.12597656,\n",
       "       -0.09912109,  0.16503906,  0.06884766, -0.18945312,  0.02832031,\n",
       "       -0.0534668 , -0.03063965,  0.11083984,  0.24121094, -0.234375  ,\n",
       "        0.12353516, -0.00294495,  0.1484375 ,  0.33203125,  0.05249023,\n",
       "       -0.20019531,  0.37695312,  0.12255859,  0.11425781, -0.17675781,\n",
       "        0.10009766,  0.0030365 ,  0.26757812,  0.20117188,  0.03710938,\n",
       "        0.11083984, -0.09814453, -0.3125    ,  0.03515625,  0.02832031,\n",
       "        0.26171875, -0.08642578, -0.02258301, -0.05834961, -0.00787354,\n",
       "        0.11767578, -0.04296875, -0.17285156,  0.04394531, -0.23046875,\n",
       "        0.1640625 , -0.11474609, -0.06030273,  0.01196289, -0.24707031,\n",
       "        0.32617188, -0.04492188, -0.11425781,  0.22851562, -0.01647949,\n",
       "       -0.15039062, -0.13183594,  0.12597656, -0.17480469,  0.02209473,\n",
       "       -0.1015625 ,  0.00817871,  0.10791016, -0.24609375, -0.109375  ,\n",
       "       -0.09375   , -0.01623535, -0.20214844,  0.23144531, -0.05444336,\n",
       "       -0.05541992, -0.20898438,  0.26757812,  0.27929688,  0.17089844,\n",
       "       -0.17578125, -0.02770996, -0.20410156,  0.02392578,  0.03125   ,\n",
       "       -0.25390625, -0.125     , -0.05493164, -0.17382812,  0.28515625,\n",
       "       -0.23242188,  0.0234375 , -0.20117188, -0.13476562,  0.26367188,\n",
       "        0.00769043,  0.20507812, -0.01708984, -0.12988281,  0.04711914,\n",
       "        0.22070312,  0.02099609, -0.29101562, -0.02893066,  0.17285156,\n",
       "        0.04272461, -0.19824219, -0.04003906, -0.16992188,  0.10058594,\n",
       "       -0.09326172,  0.15820312, -0.16503906, -0.06054688,  0.19433594,\n",
       "       -0.07080078, -0.06884766, -0.09619141, -0.07226562,  0.04882812,\n",
       "        0.07324219,  0.11035156,  0.04858398, -0.17675781, -0.33789062,\n",
       "        0.22558594,  0.16308594,  0.05102539, -0.08251953,  0.07958984,\n",
       "        0.08740234, -0.16894531, -0.02160645, -0.19238281,  0.03857422,\n",
       "       -0.05102539,  0.21972656,  0.08007812, -0.21191406, -0.07519531,\n",
       "       -0.15039062,  0.3046875 , -0.17089844,  0.12353516, -0.234375  ,\n",
       "       -0.10742188, -0.06787109,  0.01904297, -0.14160156, -0.22753906,\n",
       "       -0.16308594,  0.14453125, -0.15136719, -0.296875  ,  0.22363281,\n",
       "       -0.10205078, -0.0456543 , -0.21679688, -0.09033203,  0.09375   ,\n",
       "       -0.15332031, -0.01550293,  0.3046875 , -0.23730469,  0.08935547,\n",
       "        0.03710938,  0.02941895, -0.28515625,  0.15820312, -0.00306702,\n",
       "        0.06054688,  0.00497437, -0.15234375, -0.00836182,  0.02197266,\n",
       "       -0.12109375, -0.13867188, -0.2734375 , -0.06835938,  0.08251953,\n",
       "       -0.26367188, -0.16992188,  0.14746094,  0.08496094,  0.02075195,\n",
       "        0.13671875, -0.04931641, -0.0100708 , -0.00369263, -0.10839844,\n",
       "        0.14746094, -0.15527344,  0.16113281,  0.05615234, -0.05004883,\n",
       "       -0.1640625 , -0.26953125,  0.4140625 ,  0.06079102, -0.046875  ,\n",
       "       -0.02514648,  0.10595703,  0.1328125 , -0.16699219, -0.04907227,\n",
       "        0.04663086,  0.05151367, -0.07958984, -0.16503906, -0.29882812,\n",
       "        0.06054688, -0.15332031, -0.00598145,  0.06640625, -0.04516602,\n",
       "        0.24316406, -0.07080078, -0.36914062, -0.23144531, -0.11914062,\n",
       "       -0.08300781,  0.14746094, -0.05761719,  0.23535156, -0.12304688,\n",
       "        0.14648438,  0.13671875,  0.15429688,  0.02111816, -0.09570312,\n",
       "        0.05859375,  0.03979492, -0.08105469,  0.0559082 , -0.16601562,\n",
       "        0.27148438, -0.20117188, -0.00915527,  0.07324219,  0.10449219,\n",
       "        0.34570312, -0.26367188,  0.02099609, -0.40039062, -0.03417969,\n",
       "       -0.15917969, -0.08789062,  0.08203125,  0.23339844,  0.0213623 ,\n",
       "       -0.11328125,  0.05249023, -0.10449219, -0.02380371, -0.08349609,\n",
       "       -0.04003906,  0.01916504, -0.01226807, -0.18261719, -0.06787109,\n",
       "       -0.08496094, -0.03039551, -0.05395508,  0.04248047,  0.12792969,\n",
       "       -0.27539062,  0.28515625, -0.04736328,  0.06494141, -0.11230469,\n",
       "       -0.02575684, -0.04125977,  0.22851562, -0.14941406, -0.15039062],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv[\"car\"] # https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaUsF1Hbzds8",
    "outputId": "a52e38a9-1a88-42e0-fcea-88881550eafa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(w2v.wv[\"car\"]) # un embedding q tiene 300 vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyJyLhkhNJNX"
   },
   "source": [
    "# Armamos la matriz de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlY6kxXlUv_b",
    "outputId": "f8d1d2f7-e40a-4ea1-b771-68bdfdf0319b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30004, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embed_dim=300\n",
    "embedding_matrix=np.zeros([num_words+4,embed_dim])\n",
    "for word, idx in index.items():\n",
    "  if idx <= num_words and word in w2v.wv:\n",
    "    embedding_matrix[idx+INDEX_FROM,:]=w2v.wv[word]\n",
    "    \n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qYXiXIHNbaK",
    "outputId": "1432d485-d357-42c6-c54f-2a132d3bfc77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[100][:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PJzpmFbRL7j"
   },
   "source": [
    "# Hacemos que todos los reviews tengan el mismo largo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_HdJ8KrrZszC"
   },
   "outputs": [],
   "source": [
    "maxlen=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6r9jiL4QarNw"
   },
   "outputs": [],
   "source": [
    "#pad_sequences is used to ensure that all sequences in a list have the same length. By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence.\n",
    "data = pad_sequences(data, maxlen=maxlen, value=0.0) # data era training data + test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiL4twmwas3F",
    "outputId": "2f0c6c15-09e4-4692-c18d-acb238d1fdfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoPdGTyaaudk",
    "outputId": "6924556a-3774-4fac-a653-9edf06daf141"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8cJ6McFOF_u",
    "outputId": "2820a8c2-e1e6-4330-d7b8-5ea74a336590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     1,   194,  1153,   194,  8255,    78,   228,     5,\n",
       "           6,  1463,  4369,  5012,   134,    26,     4,   715,     8,\n",
       "         118,  1634,    14,   394,    20,    13,   119,   954,   189,\n",
       "         102,     5,   207,   110,  3103,    21,    14,    69,   188,\n",
       "           8,    30,    23,     7,     4,   249,   126,    93,     4,\n",
       "         114,     9,  2300,  1523,     5,   647,     4,   116,     9,\n",
       "          35,  8163,     4,   229,     9,   340,  1322,     4,   118,\n",
       "           9,     4,   130,  4901,    19,     4,  1002,     5,    89,\n",
       "          29,   952,    46,    37,     4,   455,     9,    45,    43,\n",
       "          38,  1543,  1905,   398,     4,  1649,    26,  6853,     5,\n",
       "         163,    11,  3215, 10156,     4,  1153,     9,   194,   775,\n",
       "           7,  8255, 11596,   349,  2637,   148,   605, 15358,  8003,\n",
       "          15,   123,   125,    68, 23141,  6853,    15,   349,   165,\n",
       "        4362,    98,     5,     4,   228,     9,    43,     2,  1157,\n",
       "          15,   299,   120,     5,   120,   174,    11,   220,   175,\n",
       "         136,    50,     9,  4373,   228,  8255,     5, 25249,   656,\n",
       "         245,  2350,     5,     4,  9837,   131,   152,   491,    18,\n",
       "           2,    32,  7464,  1212,    14,     9,     6,   371,    78,\n",
       "          22,   625,    64,  1382,     9,     8,   168,   145,    23,\n",
       "           4,  1690,    15,    16,     4,  1355,     5,    28,     6,\n",
       "          52,   154,   462,    33,    89,    78,   285,    16,   145,\n",
       "          95], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vemos un ejemplo de como queda con pad sequences\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "H9HdnsE2awBy"
   },
   "outputs": [],
   "source": [
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ri0xt9ueaxlK",
    "outputId": "d4fe95a9-e006-449d-c810-ee89a5a8b00a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Nd_FmZGRVLJ"
   },
   "source": [
    "# Armamos el modelo con una Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CjoQz25NazxB"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pFwEF2mN2PIC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8YA817yWHBs",
    "outputId": "92a0fa25-df30-47ba-f9c1-327b26407450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 300)         9001200   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1000, 64)          134464    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 500, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 500, 128)          57472     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,197,297\n",
      "Trainable params: 196,097\n",
      "Non-trainable params: 9,001,200\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_words=num_words+4\n",
    "num_filters=64\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(num_filters*2, 7, activation='relu', padding='same'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
    "\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLQU6Vm8Y827",
    "outputId": "279b2183-ff35-4570-da85-57d2a75b8027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 47s 28ms/step - loss: 0.3813 - accuracy: 0.8235 - val_loss: 0.2716 - val_accuracy: 0.8833\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.2703 - accuracy: 0.8889 - val_loss: 0.2486 - val_accuracy: 0.8982\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.2230 - accuracy: 0.9100 - val_loss: 0.2553 - val_accuracy: 0.8947\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.1799 - accuracy: 0.9304 - val_loss: 0.2448 - val_accuracy: 0.9034\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.1425 - accuracy: 0.9459 - val_loss: 0.2901 - val_accuracy: 0.8944\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 0.1130 - accuracy: 0.9574 - val_loss: 0.2727 - val_accuracy: 0.9007\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 0.0934 - accuracy: 0.9653 - val_loss: 0.3064 - val_accuracy: 0.9011\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.0765 - accuracy: 0.9719 - val_loss: 0.3414 - val_accuracy: 0.8903\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 0.0671 - accuracy: 0.9751 - val_loss: 0.3332 - val_accuracy: 0.8996\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.0570 - accuracy: 0.9790 - val_loss: 0.3868 - val_accuracy: 0.8983\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 0.0496 - accuracy: 0.9806 - val_loss: 0.3983 - val_accuracy: 0.8957\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.3798 - val_accuracy: 0.8951\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 0.0410 - accuracy: 0.9849 - val_loss: 0.4643 - val_accuracy: 0.8943\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.0370 - accuracy: 0.9859 - val_loss: 0.4658 - val_accuracy: 0.8957\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.0380 - accuracy: 0.9860 - val_loss: 0.4567 - val_accuracy: 0.8997\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.0341 - accuracy: 0.9879 - val_loss: 0.5108 - val_accuracy: 0.8955\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.5377 - val_accuracy: 0.8973\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 0.5487 - val_accuracy: 0.9001\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.6545 - val_accuracy: 0.8883\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.5512 - val_accuracy: 0.8975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe060282210>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  loss: 0.0240 - accuracy: 0.9907 - val_loss: 0.6539 - val_accuracy: 0.8938\n",
    "model.fit(data,targets,batch_size=32,epochs=20,validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjETNkn_bauv",
    "outputId": "cafcae76-2fa8-4967-b9c1-d2f5582aa4b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00],\n",
       "       [1.0966387e-17],\n",
       "       [9.6484932e-19],\n",
       "       ...,\n",
       "       [2.0447390e-09],\n",
       "       [9.9997675e-01],\n",
       "       [4.4132885e-05]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proximos pasos:\n",
    "# 1. predecir algo\n",
    "# evaluate the model\n",
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frwMFWK1tr9G"
   },
   "source": [
    "# SAVE / LOAD MODEL\n",
    "\n",
    "Keras separates the concerns of saving your model architecture and saving your model weights.\n",
    "\n",
    "Model weights are saved to HDF5 format. This is a grid format that is ideal for storing multi-dimensional arrays of numbers.\n",
    "\n",
    "The model structure can be described and saved using two different formats: JSON and YAML.\n",
    "\n",
    "--------------------\n",
    "**Keras also supports a simpler interface to save both the model weights and model architecture together into a single H5 file.**\n",
    "\n",
    "Saving the model in this way includes everything we need to know about the model, including:\n",
    "\n",
    "    Model weights.\n",
    "    Model architecture.\n",
    "    Model compilation details (loss and metrics).\n",
    "    Model optimizer state.\n",
    "\n",
    "This means that we can load and use the model directly, without having to re-compile it as we did in the examples above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlgelEhknz9U",
    "outputId": "f652799f-d84e-4f5c-bdba-f2a5238d7e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------- SAVE MODEL --------------------\n",
    "# save model and architecture to single file\n",
    "model.save(\"word2vec_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "RKXvht6Hvjrb"
   },
   "outputs": [],
   "source": [
    "# lo copiamos al drive\n",
    "%cp  /content/word2vec_model.h5 /content/drive/MyDrive/word2vec_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "BvXWQDyVwU7b"
   },
   "outputs": [],
   "source": [
    "# ----------------------------- LOAD MODEL ------------------------\n",
    "from tensorflow.keras import models \n",
    "\n",
    "%cp  /content/drive/MyDrive/word2vec_model.h5 /content/word2vec_model.h5\n",
    "my_h5_saved_model = models.load_model('/content/word2vec_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0Qm1s-M8_3h"
   },
   "source": [
    "# TENSORBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "sAhV001U1rZ6"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Y136TFpt8sSq"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "id": "me17JK8v1Uoc",
    "outputId": "9abc9763-60f7-43c4-b038-7a3543710453"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        (async () => {\n",
       "            const url = new URL(await google.colab.kernel.proxyPort(6009, {'cache': true}));\n",
       "            url.searchParams.set('tensorboardColab', 'true');\n",
       "            const iframe = document.createElement('iframe');\n",
       "            iframe.src = url;\n",
       "            iframe.setAttribute('width', '100%');\n",
       "            iframe.setAttribute('height', '800');\n",
       "            iframe.setAttribute('frameborder', 0);\n",
       "            document.body.appendChild(iframe);\n",
       "        })();\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "nlp_lab02_Word2Vec_Embeddings_antonelli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
